{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGen RNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLwZrSFVFWvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8f7c8fa-3884-4249-c059-d89d4a20fcb9"
      },
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n3omtzYFhtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1gM6JsfGM45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "0ddcf8d4-eabf-47c1-fe88-6d0eef81dd9e"
      },
      "source": [
        "from textgenrnn import textgenrnn\n",
        "\n",
        "textgen = textgenrnn()\n",
        "textgen.generate()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Make me a serious ground and destroyed the world in the Sanders and the same character was a good camera with the face of the bottom/song about the town down on the competition for the most cat? I want to see a school early than the burger than you who can be a recent plant for the first time and \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvZhmruyNTlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "outputId": "61164978-e95c-48f1-8668-8c808da4345c"
      },
      "source": [
        "textgen.train_from_file('/content/textgenrnn/datasets/hacker_news_2000.txt', num_epochs=1)\n",
        "textgen.generate()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2,000 texts collected.\n",
            "Training on 83,501 character sequences.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/1\n",
            "652/652 [==============================] - 173s 266ms/step - loss: 1.8799\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "A Procusion of Stop Show How I Warmat Source\n",
            "\n",
            "Show HN: A Problem Company Companies At Warnaphing Company\n",
            "\n",
            "A Procusion and Source Servers – A Broken Computer is a Program and PayPal and Show Holl How I Free Show How I For Home Show\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "An easten app is there I Happended\n",
            "\n",
            "How It's Uber Money\n",
            "\n",
            "Libral Progrem is Santa Building Warmard Based on The First Story\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Theman's Show Hack\n",
            "\n",
            "Chinala copypes\n",
            "\n",
            "Hearing –vot pointed activity and opporing popular\n",
            "\n",
            "Landit of More-Houstar Interview\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSuTOYtFNd86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "58fc374b-2b06-4c1c-9950-1606f27372e9"
      },
      "source": [
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "fulltext_path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "\n",
        "textgen.reset()\n",
        "textgen.train_from_largetext_file(fulltext_path, new_model=True, num_epochs=1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 0us/step\n",
            "Training new model w/ 2-layer, 128-cell LSTMs\n",
            "Training on 600,852 character sequences.\n",
            "Epoch 1/1\n",
            "4694/4694 [==============================] - 1308s 279ms/step - loss: 2.3386\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "iritual stand the most all the spiritual man the man the experience of the spiritual is the man the man the most all the stated the same and the most are man the stands the say the man the spiritual stand the spiritual man in the beaded and distrust of the superfical the man the most in the superior\n",
            "\n",
            "and the most in the spection of the many the most in the say the man the mans the say the man man the man the stated and the man the present in the self and the man the most in the spiritual man and the man and the stated to be far the most the more the man the seem of the say the most in the superf\n",
            "\n",
            "e same the are the man the spirits and all the same the spiritual that the spiritual man all the man the most in the most in the stated the say the most all the mans the man the spiritual in the spiritual far the man in the man the man the most all the sacrifice of the spection of the most in the sp\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            " has when the more of man in its experiently the state the funteretting into the sace of the probated the superfication as the stated there is man bear the\n",
            "perhaps this seems this cartural the superior of the many think\n",
            "in the beavontion of the same distrust when the state, and inder the make even t\n",
            "\n",
            "y a concernation in this deligion, and spirits in man the most in the man the person the say the the spiritaral not noble spection, that the most spority, in in the that seem the readations the states thoughts of the expervent in the superit, and the eacations and spirits of human strect, and the sp\n",
            "\n",
            " staid, the readay and man seem all the his are for the sees of the soul regard the readon states that is a past indivild the stated belies in the serse of the more same the more is a believed, may the most into the\n",
            "most have the his as the superiar and maning of the being the stated as the deality \n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            " once, have realnernations\n",
            "so concail lort forselve of the spirit elmans--the scectianns tame, \n",
            "   Tay through,\" luts inthuctional beaction why is world, racue\n",
            "inalify I Gochars--and not in it fal, a man evolopnation in this\n",
            "rifice, at breacting, a deel, I hortory, to fill a long into expervent usil\n",
            "\n",
            "instants: finding to may nol\n",
            "fainst mide the sick these\n",
            "lat beliem him to prosons a tarres as very looks as\n",
            "free, comperators, uponal, eye indriently. The fall, its ustimetth is fards obspalier there notder of favioriet.=\n",
            " FIMLOD forder, at-reed. The Firroved, man him spicuous, what is a under to sh\n",
            "\n",
            "hat mats and regard vartly,\n",
            "and find, glears eafters oneself, with be may sceplicions of malents midethys,\n",
            "thinkind RIESY\" that way to get is their leaged be more standsishy as the say make pained for, the mottinga eade justion this\n",
            "a fuch to go sinul favur, that,\n",
            "every\n",
            "no matter borth, that them wh\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17EEWes_PPPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4ed6eba-c790-4d5c-ff7f-3cf4d9384bd7"
      },
      "source": [
        "textgen.reset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method textgenrnn.reset of <textgenrnn.textgenrnn.textgenrnn object at 0x7f824ef66978>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFyQBrvyUprl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "cd5684b2-cf64-442d-b5df-8d1f2053a9f0"
      },
      "source": [
        "textgen.generate(5, prefix=\"Apple\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "he\n",
            "indristical man indived in the sacrifice, the inderstant in in the sight indiving of the pay be of the dreart the called in the tarties and means the\n",
            "sumpation that a readation the more interness their\n",
            "part of this man the stands of more that the part of the many a the\n",
            "pastricated in all at the r\n",
            "\n",
            "anify, the superfical imposse such mast of the spiritual indiver all the are the most, in the sacturing the positation of their nature and in the instances, the man of the bearity all a readom and statent and marthy of a philosophy, which a self all the constations in\n",
            "the readed to be suffering in t\n",
            "\n",
            "n the gromes the more the marting the spiritable and the most in this is the master, at is the stated of the most in the possible man respecture, and the matter, and the most one the self-may the Sphaps and superfocated to be stand and the many man to be considitual for the man, his indivind man far\n",
            "\n",
            "aster, and are and effect and are the spiritual many the rights, from the most all all be than man the readation of the spiritual\n",
            "in the master for the most in the subjection in the supervicial at the person and all the man orher the\n",
            "the most in the suplicious spirits and mattement spirit, manifical\n",
            "\n",
            "an a religion to be man dirded and man, which the master, and the mander and the far the master--the spiritual make to perhaps all maning of the reason call than the bearing and not are the most are all those which is life the that the man be spicutation in the deen the man the man the strong the st\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ9YlV-iU57_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textgen.reset()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m85RrxmHVBgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "27c9a424-11a8-4bfe-b3a5-6cc68919187a"
      },
      "source": [
        "textgen.generate(5, prefix=\"Apple\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple should be a program after one of your more of it as a very sleeping thing?\n",
            "\n",
            "Apple plans to a complete community in the game in the world is a difference before actually disappointed.\n",
            "\n",
            "Apple was released and was a content of the sun and I made a time to fix up the pricech. Need to be proud of your positions of life.\n",
            "\n",
            "Apple seeing a game to a lot of months of the child seeks to stop on the start of the world of the startup of the new business between the power and server and share it was the first time in a post with the resort of the rankey and this is a company to see if you will let me do anything. It's not \n",
            "\n",
            "Apple is the only one with Texas and Star Wars Bank and the Rare of The Week 2 - Company\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5igW81buVFk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textgen.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYV9S36JVKPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "ba58e00a-caef-4241-f3c2-cea8b58516a7"
      },
      "source": [
        "textgen.generate(4, prefix='Bigil')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bigily Master is a long time that you would be the first time because of the characters says they say that they are a family about the start of a stream and we all have a company think in the last night.\n",
            "\n",
            "Bigile Strong Star Wars\n",
            "\n",
            "Bigilisi Friday, I just realized that the most depression was a break of the action better than the same shitty check of the state with a bit of the super looking at the device.\n",
            "\n",
            "Bigily ends for the dead and the best friend was the new thing that are bored and seems to play the point of the new trailer\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NClrrJ_zVrwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}